# Deber_AW_Jordi

Durante los años noventa, el primer metamedio que imaginaron Kay y Goldberg en 1977 fue transformándose lentamente en realidad.Empezando por el Sketchpad y ampliándose a las últimas versiones del software de medios, gran parte de los medios fisicos fueron simulados con todo lujo de detalles y durante el proceso se les agregaron muchas nuevas propiedades.En paralelo, se estaban inventando toda una serie de medios informáticos absolutamente nuevos sin precedentes fisicos: por ejemplo, el espacio en 3D navegable e interactivo (Ivan Sutherland), la multimedia interactiva (Aspen Movie Map del Architecture Machine Group); el hipertexto y la hipermedia (Ted Nelson); el cinenarrativo interactivo (Graham Weinbren); internet (Licklider, Bob Taylor, Larry Roberts y otros); la World Wide Web (Tim Berners-Lee); los servicios medios sociales de (SixDegrees.com)145, las plataformas de autoría colaborativa a gran escala como la Wikipedia (Jimmy Wales y Larry Sanger), etc.Asimismo, se desarrollaron otras técnicas esenciales de nuevo euño para la generación, manipulación y presentación de medios que tampoco disponían de equivalentes físicos anteriores, como la generación algoritmica de imágenes lineales, el renderizado fotorrealista en 3D o restricciones ya introducidas en Sketchpad.En pocas palabras, se hizo realidad la visión de Kay del ordenador como metamedio: una plataforma que albergaba una multitud de medios existentes y nuevos.(Y utilizo aquí la palabra etapas en sentido lógico y no histórico.) Se trata de una cuestión que, al menos que yo haya observado, los inventores de los medios informáticos (Sutherland, Nelson, Engelbart, Kay y todos los que trabajaron con ellos) no abordaron en sus escritos.Sin embargo, en tanto en cuanto fueron ellos los que establecieron las condiciones para que existieran,El debate sobre el metamedio ordenador del final del artículo de 1977 de Kay y Goldberg puede dar la impresión de que se iba a desarrollar a través de añadidos, a medida que los usuarios formaran nuevos tipos de medios para amoldarse a necesidades empleando las herramientas proporcionadas con el ordenador personal Dynabook.A juzgar por la evolución real del metamedio ordenador los siguientes treinta años, parece que atinaron con su conclusión.Por ejemplo, si analizamos el uso de los medios informáticos en el arte que empieza durante la segunda mitad de la década de 1950 (composición musical y generación algoritmica de imágenes), en 2003 el reconocido libro de Christine Paul Digital Art ya enumeraba una decena deEn esta línea, un artículo de la Wikipedia sobre «software colaborativo» ofrece una lista de una docena de tipos de programas (y evidentemente existen decenas o centenares de productos distintos para cada tipo)146 Otro artículo de la Wikipedia sobre software social-147 enumera veinte clases principales de medios sociales (mensajería instantánea, chat de texto, groupware, blogs, etc.), y en la práctica ninguno de ellos existía en los primeros tiempos de la informática durante los años sesenta.Siguiendo con estos ejemplos de añadidos, un diseño gráfico típico creado hoy en día con aplicaciones de software puede que dé la sensación de ser una simple suma de medios anteriores: un bolígrafo que dibuja + pintura al óleo+ una fotografia + un collage.A medida que aparecen nuevas opciones (porque la industria del software ha sacado una nueva versión o porque hemos adquirido unos complementos o plugins por nuestracuenta), se nos presentan como añadidos para los mismos menús.No obstante, estos procesos de adición y acumulación no son los únicos que definen la evolución del ordenador como metamedio.Sí es cierto que desempeñan un papel, pero me parece que no epnstituyen el núcleo de la transformación (o, si se quiere, la mutación) de este metamedio (y, por extensión, de toda la cultura moderna generada a través del software) en las tres décadas siguientes al artículo fundacional de Kay y Goldberg de 1977 (año que utilizo, claro que tan solo simbólicamente, para marcar el final de la primera etapa de invención de medios»).Creo que el nuevo periodo que empieza a finales de los setenta representa una segunda fase, notablemente distinta, de la Ievolución del ordenador como metamedio, después de su primera fase de invención e implantación práctica inicial.Una vez los ordenadores se transformaron en cómodas casas donde habitaban un sinfin de medios simulados y nuevos, es natural esperar que empezarían a generar híbridos.Y esto es exactamente lo que ha venido sucediendo en esta nueva etapa de evolución de los medios.Tanto los simulados como los nuevos de verdad (texto, hipertexto, fotografias fijas, video digital, animación en 2D y 3D, espacios navegables en 3D, mapas, información defotografia fija y otros medios para crear una representación hibrida que los ingenieros de Google llaman una interfaz en 3D del planeta».Una secuencia de gráficos en movimiento puede combinar contenidos y técnicas de medios diferentes, como video de imágenes reales (live action), animación por ordenador en 3D, animación en 2D, pintura y dibujos.
¿Qué permite la hibridación de las técnicas de creación, edición y navegación de medios?Para empezar a responder esta pregunta, debemos volver a plantearnos qué entraña la simulación de medios fisicos gracias al software.Una respuesta ingenua sería que los ordenadores simulan los objetos verdaderos de estos medios.Lo que el software simula son las técnicas fisicas, mecánicas o electrónicas empleadas para navegar, crear, editar e interaccionar con los datos de los medios.(Y, por supuesto, también los amplía y los refuerza, como ya hemos visto con detenimiento en la Parte 1.) Por ejemplo, la simulación de la imprenta incorpora las técnicas de escritura y corrección de textos (copiar, cortar, pegar, insertar); las técnicas de modificación de la apariencia de este texto (cambiar fuentes o el color del texto), así como la maquetación del documento (definir márgenes, insertar números de página, etc.); y las técnicas de visualización del documento final (ir a la siguiente página, visualizar múltiples páginas, usar el zoom, marcar página).simulación en software del cine incluye todas las técnicas de la cinematografia, como el enfoque definido por el usuario, la gramática de los movimientos de cámara (desplazamiento horizontal, traveling en dolly, zoom), el objetivo concreto que determina qué parte de una escena virtual verá la cámara, etc.La simulación del vídeo analógico engloba una serie de órdenes de navegación: reproducir adelante, reproducir rebobinando, avanzar, mostrar en bucle, etc.En resumen: simular un medio en software significa simular sus herramientas e interfaces, más que su «material».Antes de su softwarización, las técnicas disponibles en un medio determinado formaban parte de su «hardware».inscribir la información en algún material, modificar dicha información y, si no podía accederse directamente a la información a través de los sentidos humanos, como en el caso de la grabación de audio, presentarla.Conjuntamente, el material y los instrumentos determinaban las opciones que ofrecía el medio en cuestión.Por ejemplo, las técnicas disponibles para escribir venían determinadas por las propiedades del papel y de los instrumentos para la escritura, como la pluma o la máquina de mecanografiar.(Por ejemplo, el papel permite que se inscriban marcas en su superficie y otras marcas encima de éstas; las marcas pueden borrarse si las hacemos con un lápiz en lugar de un bolígrafo; etc.) Del mismo modo, las técnicas de la producción cinematográfica estaban determinadas por las propiedades de laComo cada medio.utilizaba sus propios materiales e instrumentos físicos, mecánicos o electrónicos, cada uno también desarrollaba sus propias técnicas, que raras veces coincidian.Dado que las técnicas de medios formaban parte de un hardware incompatible y muy específico, esto impedía su hibridación.Por ejemplo, podíamos borrar con tipex una palabra al mecanografiar con máquina y teclear encima, pero no con la película ya expuesta.La simulación en software libera las técnicas de creación e interacción de medios de su hardware respectivo.Las técnicas se traducen a software, con lo que cada una se convierte en un algoritmo diferenciado.¿Y qué sucede con los materiales fisicos de cada ámbito?Podría pensarse que se eliminan en el proceso de simulación, cuando en realidad, los algoritmos de los medios, como cualquier tipo de software, funcionan con un único material: los datos digitales, a saber, los números.materiales de los diversos medios no desaparecen en la nada.En vez de una variedad de materiales fisicos, los medios informáticos utilizan distintas vías de codificación y almacenamiento de la información: diferentes estructuras de datos.Y con ello llegamos al punto decisivo: En lugar de un gran número de materiales fisicos, las simulaciones en software emplean un reducido número de estructuras de datos.(Un apunte sobre el uso que doy al término «estructura de datos».En el estudio de la informática, una estructura de datos se define como «una determinada forma de guardar y organizar datos en un ordenador para su uso eficiente» 185 Algunos ejemplos de estructuras de datos son las matrices, las listas o los árboles.a representaciones «de nivel superior que son vitales para los medios informáticos actuales: una imagen de mapa de bits, una imagen vectorial, un modelo poligonal en 3p, modelos NURBS, un archivo de texto, HTML, XML y algunos más.Si bien las industrias de la informática, los medios y la cultura giran alrededor de estos formatos, carecen de nombre estándar para denominarlos.Para mi el término «representación tiene una excesiva connotación cultural,mientras que «tipo de datos suena estrictamente técnico.Yo prefiero «estructura de datos» porque tiene un significado especifico en la ciencia computacional y al mismo tiempo en las humanidades: la parte de la «estructura».experimentamos como «medio», «contenido» u «objeto cultural» técnicamente es un conjunto de datos organizados de una manera determinada.)Pensemos en todos los tipos de materiales distintos que pueden utilizarse para crear imágenes en 2D, desde la piedra, el papel de pergamino o el lienzo, a las decenas de clases de papel que podemos encontrar en cualquier tienda de material para manualidades hoy en día.
Los híbridos de medios no se limitan a determinadas aplicaciones de software, interfaces de usuario, proyectos artísticos o páginas web.Si estoy en lo cierto al afirmar que la hibridez representa la próxima fase lógica de la evolución de los medios informáticos después de la primera etapa de simulación de los medios físicos individuales en un ordenador, lo normal sería que la detectáramos en muchas disciplinasEn este capitulo me sumergiré a fondo en un único ámbito cultural (el del diseño de imágenes en movimiento), analizando cómo el diseño y la estética de las imágenes en movimiento cambiaron drásticamente durante los años noventa.A mediados de los noventa, los medios fisicos simulados para la producción de imágenes tanto fijas como en movimiento (la fotografia cinematográfica, la animación, el diseño gráfico, la tipografia), los nuevos medios informáticos (la animación en 3D) y las nuevas técnicas informáticas (la composición, los distintos niveles de transparencia) confluyeron en un único entorno de software: los programas de software compatibles que se ejecutaban en una estación de trabajo personal o un ordenador personal.diseñadores empezaron a trabajar sistemáticamente en este entorno, utilizando el software para generar elementos individuales y para agruparlos.El resultado fue la aparición de un nuevo lenguaje visual que no tardó en erigirse en la norma.Hoy en día este lenguaje domina los medios visuales que se producen en decenas de países.Lo vemos todos los días en los anuncios, los videoclips, los gráficos televisivos, los créditos de las películas, las interfaces interactivas de los móviles u otros dispositivos, los menús dinámicos, las páginas web animadas, los gráficos para contenido de medios móvil y otros tipos de breves películas animadas no narrativas y secuencias de imágenes en movimiento que en la netualidadproducen en todo el mundo profesionales de los medios, entre ellos empresas, diseñadores y artistas particulares, y estudiantes.En total, calculo que al menos el 50� las obras con imágenes en movimiento de corta duración exhiben este lenguaje.En este capítulo me dispongo a analizar lo que yo considero algunas de sus características definitorias: una nueva estética visual híbrida, una integración sistemática de las anteriores técnicas de medios no compatibles, un uso del espacio en 3D como plataforma para el diseño de medios, un cambio constante en cada dimensión visual y una amplificación de las técnicas cinematográficas.distintos medios previamente diferenciadas dentro de una misma imagen.He aquí un ejemplo de cómo la lógica de la hibridez de medios reestructura gran parte de la cultura como un todo.Los lenguajes del diseño, la tipografia, la animación, la pintura y la cinematografia confluyen en el ordenador.Así pues, además de ser un metamedio tal como lo formuló Kay, también podemos llamar al ordenador una plataforma de metalenguaje: el lugar donde se aúnan muchos lenguajes culturales de la modernidad y empiezan a generar nuevos híbridos.Animación de los titulos de crédito iniciales de la serie de televisión Mad Men. Imaginary Forces, 2007.¿Cómo surgió este lenguaje?Creo que si echamos un vistazo al software que se utiliza en la producción de imágenes en movimiento encontraremos muchas claves para entender su apariencia actual.este análisis jamás podremos dejar atrás los tópicos que circulan sobre la cultura contemporánea (posmoderna, global, remezcla, etc.) y describir con todas las letras los lenguajes particulares de distintos ámbitos del diseño para entender las causas que hay detrás y su evolución a lo largo del tiempo.Dicho de otra manera, me parece que la teoría del software», que es lo que este libro pretende vertebrar y poner en práctica, no es un lujo, sino una necesidad.A pesar de que las transformaciones quepresentaré han necesitado de muchos desarrollos tecnológicos y sociales (hardware, software, prácticas de producción, procesos de trabajo, nuevos perfiles y ámbitos profesionales), haremos bien en subrayar una aplicación de software concreta que ha ocupado el centro de este devenir de acontecimientos.En este capítulo echaremos un vistazo muy de cerca a su interfaz, herramientas y su uso característico en el diseño de medios.After Effects apareció en 1993 y fue el primer programa de software diseñado para realizar animación, composición y efectos especiales en un ordenador personal229.Su extensa influencia sobre la producción de imágenes en movimiento es comparable al impacto que han tenido Photoshop e Illustrator sobre la fotografia, la ilustración y el diseño gráfico.Sin duda, After Effects tiene sus competidores.En los noventa las empresas también empleaban con bastante frecuencia otros programas más caros, de «gama alta», como Flame, Inferno o Paintbox, que se ejecutaban en estaciones de trabajo con gráficos especializados y todavía se siguen utilizando.En los dos mil, hubo ciertos programas de la misma categoría de precios que After Effects, como Motion de Apple, Combustion de Autodesk o Flash de Adobe, que se disputaron el dominio de After Effects.transformación de la cultura de la imagen en movimiento.(Cuando busqué en internet «mejor software gráficos movimiento y lei las respuestas a esta pregunta en diversos foros, el primer programa que aparecía siempre mencionado era After Effects.En otro ejemplo, cuando en 2012 Imaginary Forces, la empresa más ligada al auge de los gráficos en movimiento durante los noventa, hizo públicas unas convocatorias de vacantes para sus despachos de Los Angeles
